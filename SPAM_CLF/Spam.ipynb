{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from bs4 import BeautifulSoup\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please perform the following steps :&lt;div&gt;&lt;br&gt;&lt;...</td>\n",
       "      <td>Not Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;div class=\"post-text\" itemprop=\"text\"&gt;\\r\\n&lt;p&gt;...</td>\n",
       "      <td>Not Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Could you please give us following &amp;nbsp;detai...</td>\n",
       "      <td>Not Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you can also use&lt;br&gt;&lt;br&gt;import os.path&lt;br&gt;os.p...</td>\n",
       "      <td>Not Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There is no package as&amp;nbsp;&lt;b&gt;lpadmin.&amp;nbsp;&lt;...</td>\n",
       "      <td>Not Spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Data     Label\n",
       "0  Please perform the following steps :<div><br><...  Not Spam\n",
       "1  <div class=\"post-text\" itemprop=\"text\">\\r\\n<p>...  Not Spam\n",
       "2  Could you please give us following &nbsp;detai...  Not Spam\n",
       "3  you can also use<br><br>import os.path<br>os.p...  Not Spam\n",
       "4  There is no package as&nbsp;<b>lpadmin.&nbsp;<...  Not Spam"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read given data sets \n",
    "df = pd.read_csv('Data_Set.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#replace all nan value with empty string\n",
    "df['Data'].replace('', np.nan, inplace=True)\n",
    "df['Label'].replace('', np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uncomment to see no of null row\\na=np.where(pd.isnull(df))\\nfor i,j in zip(*a):\\n    print(i,j)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''uncomment to see no of null row\n",
    "a=np.where(pd.isnull(df))\n",
    "for i,j in zip(*a):\n",
    "    print(i,j)\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop all row which contain empty strings \n",
    "df.drop(df.index[752], inplace=True)\n",
    "df.drop(df.index[340], inplace=True)\n",
    "df.drop(df.index[216], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert row to numpy arrays\n",
    "X = df['Data'].values\n",
    "Y = df['Label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikrant/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://forums.fossee.in/question/31/while-creating-up-counter-block-in-python-getting-following-erros-at-cmake/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "#extract all text from each html text and stored in different list\n",
    "Data_set_X =[]\n",
    "Data_set_Y =[]\n",
    "Data_set = []\n",
    "for i in range(len(X)):\n",
    "    try:\n",
    "        soup= BeautifulSoup(X[i],'html5lib')\n",
    "        Data_set_X.append(soup.text)\n",
    "        Data_set_Y.append(Y[i])\n",
    "    except Exception as e:\n",
    "        print(i,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove all character from text which are not alpha numeric\n",
    "escapes = ''.join([chr(char) for char in range(1, 32)])\n",
    "for i in range(len(Data_set_X)):\n",
    "    Data_set_X[i]=  ' '.join([word for word in Data_set_X[i].split() if (word.isalnum() or word == '.')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Data_set_X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(Data_set_X,Data_set_Y, test_size=0.2, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counter vectorize words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words=\"english\")\n",
    "vect.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train_df = vect.transform(train_X)\n",
    "X_test_df = vect.transform(test_X)\n",
    "type(X_test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9459459459459459"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import and train naive bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "model = MultinomialNB(alpha=1.8)\n",
    "model.fit(X_train_df,train_y)\n",
    "pred = model.predict(X_test_df)\n",
    "accuracy_score(test_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Ham       0.95      0.99      0.97       175\n",
      "       Spam       0.50      0.10      0.17        10\n",
      "\n",
      "avg / total       0.93      0.95      0.93       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(test_y, pred , target_names = [\"Ham\", \"Spam\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nto open spam classifire\\npickle_in = open('spam.pickle','rb')\\nmodel = pickle.load(pickle_in)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store model in file\n",
    "with open('spam.pickle','wb') as f:\n",
    "    pickle.dump(model,f)\n",
    "with open('vect.pickle','wb') as v:\n",
    "    pickle.dump(vect,v)\n",
    "\n",
    "'''\n",
    "to open spam classifire\n",
    "pickle_in = open('spam.pickle','rb')\n",
    "model = pickle.load(pickle_in)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Uncomment for testing purpose\n",
    "def predict_spam(string):\n",
    "    vect = pickle.load(open('vect.pickle','rb'))\n",
    "    model = pickle.load(open('spam.pickle','rb'))\n",
    "    soups = BeautifulSoup(string,'html5lib')\n",
    "    string = soups.text\n",
    "    templist = string.split()\n",
    "    string= ' '.join([word for word in templist if (word.isalnum() or word == '.')])\n",
    "    return model.predict(vect.transform([string]))\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not Spam'], dtype='<U8')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string ='Please look at Scilab help files. Scilab help is available on your Scilab installation and online. \\r\\n\\r\\nApart from that, you could also watch Scilab Spoken Tutorials- http://spoken-tutorial.org/tutorial-search/?search_foss=Scilab&amp;search_language=English\\r\\n '\n",
    "predict_spam(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train_df,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9459459459459459\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Ham       0.95      1.00      0.97       175\n",
      "       Spam       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.89      0.95      0.92       185\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikrant/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "pred1 = clf.predict(X_test_df)\n",
    "print(accuracy_score(test_y, pred1))\n",
    "print(classification_report(test_y, pred1 , target_names = [\"Ham\", \"Spam\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9459459459459459\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Ham       0.95      1.00      0.97       175\n",
      "       Spam       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.89      0.95      0.92       185\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikrant/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "neigh.fit(X_train_df,train_y)\n",
    "pred2 =neigh.predict(X_test_df)\n",
    "print(accuracy_score(test_y,pred2))\n",
    "print(classification_report(test_y, pred2 , target_names = [\"Ham\", \"Spam\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
